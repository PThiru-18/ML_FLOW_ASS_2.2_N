{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Using cached mlflow-2.2.2-py3-none-any.whl (17.6 MB)\n",
      "Collecting click<9,>=7.0\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m963.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml<7,>=5.1 in /home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlflow_tutorial/lib/python3.10/site-packages (from mlflow) (6.0)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlflow_tutorial/lib/python3.10/site-packages (from mlflow) (3.1.2)\n",
      "Collecting cloudpickle<3\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: scipy<2 in /home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlflow_tutorial/lib/python3.10/site-packages (from mlflow) (1.10.1)\n",
      "Collecting importlib-metadata!=4.7.0,<7,>=3.7.0\n",
      "  Downloading importlib_metadata-6.1.0-py3-none-any.whl (21 kB)\n",
      "Collecting sqlparse<1,>=0.4.0\n",
      "  Downloading sqlparse-0.4.3-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf<5,>=3.12.0\n",
      "  Downloading protobuf-4.22.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.4/302.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting gitpython<4,>=2.1.0\n",
      "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting shap<1,>=0.40\n",
      "  Downloading shap-0.41.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (572 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.6/572.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting markdown<4,>=3.3\n",
      "  Downloading Markdown-3.4.2-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting docker<7,>=4.0.0\n",
      "  Downloading docker-6.0.1-py3-none-any.whl (147 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.5/147.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz<2023 in /home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlflow_tutorial/lib/python3.10/site-packages (from mlflow) (2022.7.1)\n",
      "Collecting requests<3,>=2.17.3\n",
      "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sqlalchemy<3,>=1.4.0\n",
      "  Downloading SQLAlchemy-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting entrypoints<1\n",
      "  Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Collecting pyarrow<12,>=4.0.0\n",
      "  Downloading pyarrow-11.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas<3 in /home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlflow_tutorial/lib/python3.10/site-packages (from mlflow) (1.5.3)\n",
      "Requirement already satisfied: packaging<24 in /home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlflow_tutorial/lib/python3.10/site-packages (from mlflow) (23.0)\n",
      "Collecting gunicorn<21\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting querystring-parser<2\n",
      "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting Flask<3\n",
      "  Downloading Flask-2.2.3-py3-none-any.whl (101 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2 in /home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlflow_tutorial/lib/python3.10/site-packages (from mlflow) (1.24.2)\n",
      "Requirement already satisfied: scikit-learn<2 in /home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlflow_tutorial/lib/python3.10/site-packages (from mlflow) (1.2.2)\n",
      "Collecting alembic<2\n",
      "  Downloading alembic-1.10.2-py3-none-any.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib<4 in /home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlflow_tutorial/lib/python3.10/site-packages (from mlflow) (3.7.1)\n",
      "Collecting databricks-cli<1,>=0.8.7\n",
      "  Downloading databricks-cli-0.17.6.tar.gz (82 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting Mako\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-extensions>=4\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting pyjwt>=1.7.0\n",
      "  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\n",
      "Collecting oauthlib>=3.1.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tabulate>=0.7.7\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlflow_tutorial/lib/python3.10/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.16.0)\n",
      "Collecting urllib3>=1.26.0\n",
      "  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.9/140.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: websocket-client>=0.32.0 in /home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlflow_tutorial/lib/python3.10/site-packages (from docker<7,>=4.0.0->mlflow) (1.5.1)\n",
      "Collecting Werkzeug>=2.2.2\n",
      "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting itsdangerous>=2.0\n",
      "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=3.0 in /home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlflow_tutorial/lib/python3.10/site-packages (from gunicorn<21->mlflow) (67.4.0)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlflow_tutorial/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlflow_tutorial/lib/python3.10/site-packages (from matplotlib<4->mlflow) (4.39.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlflow_tutorial/lib/python3.10/site-packages (from matplotlib<4->mlflow) (9.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlflow_tutorial/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlflow_tutorial/lib/python3.10/site-packages (from matplotlib<4->mlflow) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlflow_tutorial/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.0.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlflow_tutorial/lib/python3.10/site-packages (from matplotlib<4->mlflow) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlflow_tutorial/lib/python3.10/site-packages (from matplotlib<4->mlflow) (0.11.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: idna<4,>=2.5 in /home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlflow_tutorial/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (3.4)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlflow_tutorial/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlflow_tutorial/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (3.1.0)\n",
      "Collecting tqdm>4.25.0\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numba\n",
      "  Downloading numba-0.56.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting slicer==0.0.7\n",
      "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (613 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m613.7/613.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Collecting numpy<2\n",
      "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting llvmlite<0.40,>=0.39.0dev0\n",
      "  Downloading llvmlite-0.39.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.6/34.6 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: databricks-cli\n",
      "  Building wheel for databricks-cli (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for databricks-cli: filename=databricks_cli-0.17.6-py3-none-any.whl size=143222 sha256=64ae1c5953956914511882cc47a365086057743586f3adf7f260ff3ce28f7d7d\n",
      "  Stored in directory: /home/priyankathiruna/.cache/pip/wheels/7b/85/a1/37b9b24f55c1da8ea4795765de41713b8a2cccad89c866e26b\n",
      "Successfully built databricks-cli\n",
      "Installing collected packages: zipp, Werkzeug, urllib3, typing-extensions, tqdm, tabulate, sqlparse, smmap, slicer, querystring-parser, pyjwt, protobuf, oauthlib, numpy, markdown, Mako, llvmlite, itsdangerous, gunicorn, greenlet, entrypoints, cloudpickle, click, charset-normalizer, certifi, sqlalchemy, requests, pyarrow, numba, importlib-metadata, gitdb, Flask, gitpython, docker, databricks-cli, alembic, shap, mlflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.2\n",
      "    Uninstalling numpy-1.24.2:\n",
      "      Successfully uninstalled numpy-1.24.2\n",
      "Successfully installed Flask-2.2.3 Mako-1.2.4 Werkzeug-2.2.3 alembic-1.10.2 certifi-2022.12.7 charset-normalizer-3.1.0 click-8.1.3 cloudpickle-2.2.1 databricks-cli-0.17.6 docker-6.0.1 entrypoints-0.4 gitdb-4.0.10 gitpython-3.1.31 greenlet-2.0.2 gunicorn-20.1.0 importlib-metadata-6.1.0 itsdangerous-2.1.2 llvmlite-0.39.1 markdown-3.4.2 mlflow-2.2.2 numba-0.56.4 numpy-1.23.5 oauthlib-3.2.2 protobuf-4.22.1 pyarrow-11.0.0 pyjwt-2.6.0 querystring-parser-1.2.4 requests-2.28.2 shap-0.41.0 slicer-0.0.7 smmap-5.0.0 sqlalchemy-2.0.7 sqlparse-0.4.3 tabulate-0.9.0 tqdm-4.65.0 typing-extensions-4.5.0 urllib3-1.26.15 zipp-3.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. The data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The data set used in this example is from http://archive.ics.uci.edu/ml/datasets/Wine+Quality\n",
    "* P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.\n",
    "* Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.045</td>\n",
       "      <td>28.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.99280</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.37</td>\n",
       "      <td>11.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>5.8</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.031</td>\n",
       "      <td>21.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.99115</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.55</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>7.1</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.055</td>\n",
       "      <td>24.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.99410</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.43</td>\n",
       "      <td>8.9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.40</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.022</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.99150</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.37</td>\n",
       "      <td>12.6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.29</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.059</td>\n",
       "      <td>28.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>0.99610</td>\n",
       "      <td>3.54</td>\n",
       "      <td>0.59</td>\n",
       "      <td>10.3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3872</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.54</td>\n",
       "      <td>13.3</td>\n",
       "      <td>0.054</td>\n",
       "      <td>63.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.99864</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.49</td>\n",
       "      <td>8.6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>5.8</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.025</td>\n",
       "      <td>12.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.98940</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.79</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.047</td>\n",
       "      <td>42.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.99320</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>7.1</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.038</td>\n",
       "      <td>16.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.99370</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.40</td>\n",
       "      <td>11.5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>7.7</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.040</td>\n",
       "      <td>26.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.99300</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.56</td>\n",
       "      <td>10.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "192             6.8             0.280         0.36             8.0      0.045   \n",
       "741             5.8             0.200         0.30             1.5      0.031   \n",
       "361             7.1             0.365         0.14             1.2      0.055   \n",
       "740             6.9             0.390         0.40             4.6      0.022   \n",
       "2395            7.0             0.270         0.29             3.9      0.059   \n",
       "3872            7.3             0.360         0.54            13.3      0.054   \n",
       "1099            5.8             0.290         0.21             2.6      0.025   \n",
       "1615            7.5             0.190         0.49             1.6      0.047   \n",
       "445             7.1             0.320         0.32            11.0      0.038   \n",
       "2117            7.7             0.260         0.32             1.2      0.040   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "192                  28.0                 123.0  0.99280  3.02       0.37   \n",
       "741                  21.0                  57.0  0.99115  3.44       0.55   \n",
       "361                  24.0                  84.0  0.99410  3.15       0.43   \n",
       "740                   5.0                  19.0  0.99150  3.31       0.37   \n",
       "2395                 28.0                 199.0  0.99610  3.54       0.59   \n",
       "3872                 63.0                 193.0  0.99864  3.06       0.49   \n",
       "1099                 12.0                 120.0  0.98940  3.39       0.79   \n",
       "1615                 42.0                 140.0  0.99320  3.40       0.47   \n",
       "445                  16.0                  66.0  0.99370  3.24       0.40   \n",
       "2117                 26.0                 117.0  0.99300  3.21       0.56   \n",
       "\n",
       "      alcohol  quality  \n",
       "192      11.4        6  \n",
       "741      11.0        6  \n",
       "361       8.9        5  \n",
       "740      12.6        3  \n",
       "2395     10.3        5  \n",
       "3872      8.6        4  \n",
       "1099     14.0        7  \n",
       "1615     10.7        6  \n",
       "445      11.5        3  \n",
       "2117     10.8        5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"data/wine-quality.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tracking experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking stores\n",
    "MLflow supports two types of backend stores: *file store* and *database-backed* store.\n",
    "\n",
    "- Local file path (specified as file:/my/local/dir), where data is just directly stored locally. Defaults to `mlruns/`\n",
    "- Database encoded as <dialect>+<driver>://<username>:<password>@<host>:<port>/<database>. Mlflow supports the dialects mysql, mssql, sqlite, and postgresql. For more details, see SQLAlchemy database uri.\n",
    "- HTTP server (specified as https://my-server:5000), which is a server hosting an MLFlow tracking server.\n",
    "- Databricks workspace (specified as databricks or as databricks://<profileName>, a Databricks CLI profile.\n",
    "    \n",
    "### Artifact stores\n",
    "- Amazon S3\n",
    "- Azure Blob Storage\n",
    "- Google Cloud Storage\n",
    "- FTP server\n",
    "- SFTP Server\n",
    "- NFS\n",
    "- HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the MLflow tracking server by \n",
    "\n",
    "```\n",
    "mlflow server \\\n",
    "    --backend-store-uri /mnt/persistent-disk \\\n",
    "    --default-artifact-root s3://my-mlflow-bucket/ \\\n",
    "    --host 0.0.0.0\n",
    "    --port 5000\n",
    "```\n",
    "\n",
    "or use the default storage method to write to `mlruns/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow server --backend-store-uri mlruns/ --default-artifact-root mlruns/ --host 0.0.0.0 --port 5000\n",
    "remote_server_uri = \"http://127.0.0.1:5000\" # set to your server URI\n",
    "mlflow.set_tracking_uri(remote_server_uri)  # or set the MLFLOW_TRACKING_URI in the env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://127.0.0.1:5000'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.tracking.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/03/23 14:46:08 INFO mlflow.tracking.fluent: Experiment with name 'ElasticNet_wine' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlruns/637260712838838962', creation_time=1679562968193, experiment_id='637260712838838962', last_update_time=1679562968193, lifecycle_stage='active', name='ElasticNet_wine', tags={}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name = \"ElasticNet_wine\"\n",
    "mlflow.set_experiment(exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do we track?\n",
    "\n",
    "- **Code Version**: Git commit hash used for the run (if it was run from an MLflow Project)\n",
    "- **Start & End Time**: Start and end time of the run\n",
    "- **Source**: what code run?\n",
    "- **Parameters**: Key-value input parameters.\n",
    "- **Metrics**: Key-value metrics, where the value is numeric (can be updated over the run)\n",
    "- **Artifacts**: Output files in any format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "    # compute relevant metrics\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "\n",
    "def load_data(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "\n",
    "    # Split the data into training and test sets. (0.75, 0.25) split.\n",
    "    train, test = train_test_split(data)\n",
    "\n",
    "    # The predicted column is \"quality\" which is a scalar from [3, 9]\n",
    "    train_x = train.drop([\"quality\"], axis=1)\n",
    "    test_x = test.drop([\"quality\"], axis=1)\n",
    "    train_y = train[[\"quality\"]]\n",
    "    test_y = test[[\"quality\"]]\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "\n",
    "def train(alpha=0.5, l1_ratio=0.5):\n",
    "    # train a model with given parameters\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(40)\n",
    "\n",
    "    # Read the wine-quality csv file (make sure you're running this from the root of MLflow!)\n",
    "    data_path = \"data/wine-quality.csv\"\n",
    "    train_x, train_y, test_x, test_y = load_data(data_path)\n",
    "\n",
    "    # Useful for multiple runs (only doing one run in this sample notebook)    \n",
    "    with mlflow.start_run():\n",
    "        # Execute ElasticNet\n",
    "        lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "        lr.fit(train_x, train_y)\n",
    "\n",
    "        # Evaluate Metrics\n",
    "        predicted_qualities = lr.predict(test_x)\n",
    "        (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n",
    "\n",
    "        # Print out metrics\n",
    "        print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n",
    "        print(\"  RMSE: %s\" % rmse)\n",
    "        print(\"  MAE: %s\" % mae)\n",
    "        print(\"  R2: %s\" % r2)\n",
    "\n",
    "        # Log parameter, metrics, and model to MLflow\n",
    "        mlflow.log_param(key=\"alpha\", value=alpha)\n",
    "        mlflow.log_param(key=\"l1_ratio\", value=l1_ratio)\n",
    "        mlflow.log_metric(key=\"rmse\", value=rmse)\n",
    "        mlflow.log_metrics({\"mae\": mae, \"r2\": r2})\n",
    "        mlflow.log_artifact(data_path)\n",
    "        print(\"Save to: {}\".format(mlflow.get_artifact_uri()))\n",
    "        \n",
    "        mlflow.sklearn.log_model(lr, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could also do\n",
    "# with mlflow.start_run():\n",
    "#     for epoch in range(0, 3):\n",
    "#          mlflow.log_metric(key=\"quality\", value=2*epoch, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticnet model (alpha=0.500000, l1_ratio=0.500000):\n",
      "  RMSE: 0.82224284975954\n",
      "  MAE: 0.6278761410160693\n",
      "  R2: 0.12678721972772677\n",
      "Save to: /home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlruns/637260712838838962/15d47727d54a4dacb60bb1a426ddd561/artifacts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/03/23 15:14:15 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpcisdaw5w/model/model.pkl, flavor: sklearn), fall back to return ['scikit-learn==1.2.2', 'cloudpickle==2.2.1']. Set logging level to DEBUG to see the full traceback.\n"
     ]
    }
   ],
   "source": [
    "train(0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 1.2.2.\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticnet model (alpha=0.200000, l1_ratio=0.200000):\n",
      "  RMSE: 0.7859129997062341\n",
      "  MAE: 0.6155290394093895\n",
      "  R2: 0.20224631822892103\n",
      "Save to: /home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlruns/637260712838838962/dec5fd9936e94e41b68a7109d4012132/artifacts\n"
     ]
    }
   ],
   "source": [
    "train(0.2, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticnet model (alpha=0.100000, l1_ratio=0.100000):\n",
      "  RMSE: 0.7792546522251949\n",
      "  MAE: 0.6112547988118587\n",
      "  R2: 0.2157063843066196\n",
      "Save to: /home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlruns/637260712838838962/82106880f36f4e50bfa920de3d091988/artifacts\n"
     ]
    }
   ],
   "source": [
    "train(0.1, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Comparing runs\n",
    "Run `mlflow ui` in a terminal or `http://your-tracking-server-host:5000` to view the experiment log and visualize and compare different runs and experiments. The logs and the model artifacts are saved in the `mlruns` directory (or where you specified)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Packaging the experiment as a MLflow project as conda env\n",
    "\n",
    "Specify the entrypoint for this project by creating a `MLproject` file and adding an conda environment with a `conda.yaml`. You can copy the yaml file from the experiment logs.\n",
    "\n",
    "To run this project, invoke `mlflow run . -P alpha=0.42`. After running this command, MLflow runs your training code in a new Conda environment with the dependencies specified in `conda.yaml`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deploy the model\n",
    "\n",
    "Deploy the model locally by running \n",
    "\n",
    "`mlflow models serve -m mlruns/0/f5f7c052ddc5469a852aa52c14cabdf1/artifacts/model/ -h 0.0.0.0 -p 1234`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the endpoint:\n",
    "\n",
    "`curl -X POST -H \"Content-Type:application/json; format=pandas-split\" --data '{\"columns\":[\"alcohol\", \"chlorides\", \"citric acid\", \"density\", \"fixed acidity\", \"free sulfur dioxide\", \"pH\", \"residual sugar\", \"sulphates\", \"total sulfur dioxide\", \"volatile acidity\"],\"data\":[[12.8, 0.029, 0.48, 0.98, 6.2, 29, 3.33, 1.2, 0.39, 75, 0.66]]}' http://0.0.0.0:1234/invocations`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also simply build a docker image from your model\n",
    "\n",
    "`mlflow models build-docker -m mlruns/1/d671f37a9c7f478989e67eb4ff4d1dac/artifacts/model/ -n elastic_net_wine`\n",
    "\n",
    "and run the container with\n",
    "\n",
    "`docker run -p 8080:8080 elastic_net_wine`.\n",
    "\n",
    "Or you can directly deploy to AWS sagemaker or Microsoft Azure ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tagging runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mlflow.tracking.client.MlflowClient object at 0x7fa8de6455d0>\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "experiment_id = \"0\"\n",
    "run = client.create_run(experiment_id)\n",
    "artifacts = client.list_artifacts(run.info.run_id)\n",
    "for artifact in artifacts:\n",
    "    print_artifact_info(artifact)\n",
    "client.set_terminated(run.info.run_id)\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Run: data=<RunData: metrics={'mae': 0.6155290394093895,\n",
      " 'r2': 0.20224631822892103,\n",
      " 'rmse': 0.7859129997062341}, params={'alpha': '0.2', 'l1_ratio': '0.2'}, tags={'mlflow.log-model.history': '[{\"run_id\": \"dec5fd9936e94e41b68a7109d4012132\", '\n",
      "                             '\"artifact_path\": \"model\", \"utc_time_created\": '\n",
      "                             '\"2023-03-23 09:49:28.800231\", \"flavors\": '\n",
      "                             '{\"python_function\": {\"model_path\": \"model.pkl\", '\n",
      "                             '\"predict_fn\": \"predict\", \"loader_module\": '\n",
      "                             '\"mlflow.sklearn\", \"python_version\": \"3.10.8\", '\n",
      "                             '\"env\": {\"conda\": \"conda.yaml\", \"virtualenv\": '\n",
      "                             '\"python_env.yaml\"}}, \"sklearn\": '\n",
      "                             '{\"pickled_model\": \"model.pkl\", '\n",
      "                             '\"sklearn_version\": \"1.2.2\", '\n",
      "                             '\"serialization_format\": \"cloudpickle\", \"code\": '\n",
      "                             'null}}, \"model_uuid\": '\n",
      "                             '\"845da25177c842cf886fc23bd72d79d4\", '\n",
      "                             '\"mlflow_version\": \"2.2.2\"}]',\n",
      " 'mlflow.runName': 'popular-quail-266',\n",
      " 'mlflow.source.git.commit': 'e2b91c798ba6034ffb7db7939e2f229ef81bd8ec',\n",
      " 'mlflow.source.name': '/home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlflow_tutorial/lib/python3.10/site-packages/ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'priyankathiruna'}>, info=<RunInfo: artifact_uri='/home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlruns/637260712838838962/dec5fd9936e94e41b68a7109d4012132/artifacts', end_time=1679564970283, experiment_id='637260712838838962', lifecycle_stage='active', run_id='dec5fd9936e94e41b68a7109d4012132', run_name='popular-quail-266', run_uuid='dec5fd9936e94e41b68a7109d4012132', start_time=1679564968712, status='FINISHED', user_id='priyankathiruna'>>\n"
     ]
    }
   ],
   "source": [
    "# get the run\n",
    "_run = client.get_run(run_id=\"dec5fd9936e94e41b68a7109d4012132\")\n",
    "print(_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a tag to the run\n",
    "dt = datetime.now().strftime(\"%d-%m-%Y (%H:%M:%S.%f)\")\n",
    "client.set_tag(_run.info.run_id, \"deployed\", dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to a postgesql db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the db:\n",
    "    \n",
    "`sudo -u postgres psql`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a user and a database for the tracking server:\n",
    "    \n",
    "```\n",
    "CREATE DATABASE mlflow;\n",
    "CREATE USER mlflow WITH ENCRYPTED PASSWORD 'mlflow';\n",
    "GRANT ALL PRIVILEGES ON DATABASE mlflow TO mlflow;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "mlflow server --backend-store-uri postgresql://mlflow:mlflow@localhost/mlflow --default-artifact-root file:/home/tobias/Projects/mlflow_talk/pydataberlin-2019/mlruns/ -h 0.0.0.0 -p 8000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the notebook again with this tracking server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the db:\n",
    "\n",
    "`psql mlflow`\n",
    "\n",
    "`SELECT * FROM experiments;`\n",
    "\n",
    "`SELECT * FROM runs;`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
