{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. The data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The data set used in this example is from http://archive.ics.uci.edu/ml/datasets/Wine+Quality\n",
    "* P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.\n",
    "* Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16105</th>\n",
       "      <td>-122.50</td>\n",
       "      <td>37.75</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1819.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1137.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>3.4919</td>\n",
       "      <td>271800.0</td>\n",
       "      <td>NEAR OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10726</th>\n",
       "      <td>-117.81</td>\n",
       "      <td>33.64</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2404.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>868.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>11.0138</td>\n",
       "      <td>442100.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10969</th>\n",
       "      <td>-117.87</td>\n",
       "      <td>33.76</td>\n",
       "      <td>37.0</td>\n",
       "      <td>4943.0</td>\n",
       "      <td>851.0</td>\n",
       "      <td>2164.0</td>\n",
       "      <td>788.0</td>\n",
       "      <td>4.1071</td>\n",
       "      <td>311300.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>-122.27</td>\n",
       "      <td>37.87</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3218.0</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>1675.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.7464</td>\n",
       "      <td>216700.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8076</th>\n",
       "      <td>-118.19</td>\n",
       "      <td>33.83</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2246.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>3.5871</td>\n",
       "      <td>347100.0</td>\n",
       "      <td>NEAR OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7784</th>\n",
       "      <td>-118.07</td>\n",
       "      <td>33.91</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2228.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>1558.0</td>\n",
       "      <td>427.0</td>\n",
       "      <td>4.0230</td>\n",
       "      <td>157700.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8953</th>\n",
       "      <td>-118.38</td>\n",
       "      <td>34.02</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2098.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>1343.0</td>\n",
       "      <td>481.0</td>\n",
       "      <td>3.9615</td>\n",
       "      <td>268600.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>-122.27</td>\n",
       "      <td>37.77</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2252.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>1033.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>5.5337</td>\n",
       "      <td>372000.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8240</th>\n",
       "      <td>-118.19</td>\n",
       "      <td>33.77</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2103.0</td>\n",
       "      <td>727.0</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>603.0</td>\n",
       "      <td>1.6178</td>\n",
       "      <td>137500.0</td>\n",
       "      <td>NEAR OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7641</th>\n",
       "      <td>-118.28</td>\n",
       "      <td>33.81</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2755.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>2046.0</td>\n",
       "      <td>488.0</td>\n",
       "      <td>5.2034</td>\n",
       "      <td>212400.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "16105    -122.50     37.75                44.0       1819.0             NaN   \n",
       "10726    -117.81     33.64                16.0       2404.0           349.0   \n",
       "10969    -117.87     33.76                37.0       4943.0           851.0   \n",
       "462      -122.27     37.87                35.0       3218.0          1108.0   \n",
       "8076     -118.19     33.83                30.0       2246.0           552.0   \n",
       "7784     -118.07     33.91                35.0       2228.0           463.0   \n",
       "8953     -118.38     34.02                45.0       2098.0           486.0   \n",
       "545      -122.27     37.77                52.0       2252.0           388.0   \n",
       "8240     -118.19     33.77                21.0       2103.0           727.0   \n",
       "7641     -118.28     33.81                29.0       2755.0           508.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \\\n",
       "16105      1137.0       354.0         3.4919            271800.0   \n",
       "10726       868.0       329.0        11.0138            442100.0   \n",
       "10969      2164.0       788.0         4.1071            311300.0   \n",
       "462        1675.0      1000.0         1.7464            216700.0   \n",
       "8076       1032.0       548.0         3.5871            347100.0   \n",
       "7784       1558.0       427.0         4.0230            157700.0   \n",
       "8953       1343.0       481.0         3.9615            268600.0   \n",
       "545        1033.0       434.0         5.5337            372000.0   \n",
       "8240       1064.0       603.0         1.6178            137500.0   \n",
       "7641       2046.0       488.0         5.2034            212400.0   \n",
       "\n",
       "      ocean_proximity  \n",
       "16105      NEAR OCEAN  \n",
       "10726       <1H OCEAN  \n",
       "10969       <1H OCEAN  \n",
       "462          NEAR BAY  \n",
       "8076       NEAR OCEAN  \n",
       "7784        <1H OCEAN  \n",
       "8953        <1H OCEAN  \n",
       "545          NEAR BAY  \n",
       "8240       NEAR OCEAN  \n",
       "7641        <1H OCEAN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"data/housing.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tracking experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking stores\n",
    "MLflow supports two types of backend stores: *file store* and *database-backed* store.\n",
    "\n",
    "- Local file path (specified as file:/my/local/dir), where data is just directly stored locally. Defaults to `mlruns/`\n",
    "- Database encoded as <dialect>+<driver>://<username>:<password>@<host>:<port>/<database>. Mlflow supports the dialects mysql, mssql, sqlite, and postgresql. For more details, see SQLAlchemy database uri.\n",
    "- HTTP server (specified as https://my-server:5000), which is a server hosting an MLFlow tracking server.\n",
    "- Databricks workspace (specified as databricks or as databricks://<profileName>, a Databricks CLI profile.\n",
    "    \n",
    "### Artifact stores\n",
    "- Amazon S3\n",
    "- Azure Blob Storage\n",
    "- Google Cloud Storage\n",
    "- FTP server\n",
    "- SFTP Server\n",
    "- NFS\n",
    "- HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the MLflow tracking server by \n",
    "\n",
    "```\n",
    "mlflow server \\\n",
    "    --backend-store-uri /mnt/persistent-disk \\\n",
    "    --default-artifact-root s3://my-mlflow-bucket/ \\\n",
    "    --host 0.0.0.0\n",
    "    --port 5000\n",
    "```\n",
    "\n",
    "or use the default storage method to write to `mlruns/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow server --backend-store-uri mlruns/ --default-artifact-root mlruns/ --host 0.0.0.0 --port 5000\n",
    "remote_server_uri = \"http://127.0.0.1:5000\" # set to your server URI\n",
    "mlflow.set_tracking_uri(remote_server_uri)  # or set the MLFLOW_TRACKING_URI in the env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://127.0.0.1:5000'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.tracking.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/03/23 18:46:46 INFO mlflow.tracking.fluent: Experiment with name 'ElasticNet_housing_1' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlruns/930564221674376619', creation_time=1679577406541, experiment_id='930564221674376619', last_update_time=1679577406541, lifecycle_stage='active', name='ElasticNet_housing_1', tags={}>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name = \"ElasticNet_housing_1\"\n",
    "mlflow.set_experiment(exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do we track?\n",
    "\n",
    "- **Code Version**: Git commit hash used for the run (if it was run from an MLflow Project)\n",
    "- **Start & End Time**: Start and end time of the run\n",
    "- **Source**: what code run?\n",
    "- **Parameters**: Key-value input parameters.\n",
    "- **Metrics**: Key-value metrics, where the value is numeric (can be updated over the run)\n",
    "- **Artifacts**: Output files in any format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "    # compute relevant metrics\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "\n",
    "def load_data(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    housing = data\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n",
    "    housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
    "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                               labels=[1, 2, 3, 4, 5])\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "        strat_train_set = housing.loc[train_index]\n",
    "        strat_test_set = housing.loc[test_index]\n",
    "\n",
    "\n",
    "    def income_cat_proportions(data):\n",
    "        return data[\"income_cat\"].value_counts() / len(data)\n",
    "\n",
    "    train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n",
    "\n",
    "    compare_props = pd.DataFrame({\n",
    "        \"Overall\": income_cat_proportions(housing),\n",
    "        \"Stratified\": income_cat_proportions(strat_test_set),\n",
    "        \"Random\": income_cat_proportions(test_set),\n",
    "    }).sort_index()\n",
    "    compare_props[\"Rand. %error\"] = 100 * compare_props[\"Random\"] / compare_props[\"Overall\"] - 100\n",
    "    compare_props[\"Strat. %error\"] = 100 * compare_props[\"Stratified\"] / compare_props[\"Overall\"] - 100\n",
    "\n",
    "    for set_ in (strat_train_set, strat_test_set):\n",
    "        set_.drop(\"income_cat\", axis=1, inplace=True)\n",
    "\n",
    "    housing = strat_train_set.copy()\n",
    "    housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "    housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
    "    housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]\n",
    "\n",
    "    housing = strat_train_set.drop(\"median_house_value\", axis=1) # drop labels for training set\n",
    "    housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "    housing_num = housing.drop('ocean_proximity', axis=1)\n",
    "\n",
    "    imputer.fit(housing_num)\n",
    "    X = imputer.transform(housing_num)\n",
    "\n",
    "    housing_tr = pd.DataFrame(X, columns=housing_num.columns,\n",
    "                              index=housing.index)\n",
    "    housing_tr[\"rooms_per_household\"] = housing_tr[\"total_rooms\"]/housing_tr[\"households\"]\n",
    "    housing_tr[\"bedrooms_per_room\"] = housing_tr[\"total_bedrooms\"]/housing_tr[\"total_rooms\"]\n",
    "    housing_tr[\"population_per_household\"]=housing_tr[\"population\"]/housing_tr[\"households\"]\n",
    "\n",
    "    housing_cat = housing[['ocean_proximity']]\n",
    "    housing_prepared = housing_tr.join(pd.get_dummies(housing_cat, drop_first=True))\n",
    "    return housing_prepared,housing_labels\n",
    "\n",
    "    \n",
    "\n",
    "def train(alpha=0.5, l1_ratio=0.5):\n",
    "    # train a model with given parameters\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(40)\n",
    "\n",
    "    # Read the wine-quality csv file (make sure you're running this from the root of MLflow!)\n",
    "    data_path = \"data/housing.csv\"\n",
    "    housing_prepared,housing_labels = load_data(data_path)\n",
    "\n",
    "    # Useful for multiple runs (only doing one run in this sample notebook)    \n",
    "    # Create nested runs\n",
    "    #experiment_id = mlflow.create_experiment(\"experiment3\")\n",
    "    #experiment_id = mlflow.create_experiment(\"experiment5\")\n",
    "    with mlflow.start_run(\n",
    "        run_name=\"PARENT_RUN\",\n",
    "        experiment_id=experiment_id,\n",
    "        tags={\"version\": \"v1\", \"priority\": \"P1\"},\n",
    "        description=\"parent\",\n",
    "    ) as parent_run:\n",
    "        mlflow.log_param(\"parent\", \"yes\")\n",
    "        with mlflow.start_run(\n",
    "            run_name=\"CHILD_RUN\",\n",
    "            experiment_id=experiment_id,\n",
    "            description=\"child\",\n",
    "            nested=True,\n",
    "        ) as child_run:\n",
    "            mlflow.log_param(\"child\", \"yes\")\n",
    "    lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "    lr.fit(housing_prepared, housing_labels)\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    housing_predictions = lr.predict(housing_prepared)\n",
    "    lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "    lin_rmse = np.sqrt(lin_mse)\n",
    "    print(\"rmse\",lin_rmse)\n",
    "    # Print out metrics\n",
    "    print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n",
    "    print(\"  RMSE: %s\" % lin_rmse)\n",
    "    print(\"  MAE: %s\" % lin_mse)\n",
    "#         print(\"  R2: %s\" % r2)\n",
    "\n",
    "    # Log parameter, metrics, and model to MLflow\n",
    "    mlflow.log_param(key=\"alpha\", value=alpha)\n",
    "    mlflow.log_param(key=\"l1_ratio\", value=l1_ratio)\n",
    "    mlflow.log_metric(key=\"rmse\", value=lin_rmse)\n",
    "    mlflow.log_metrics({\"mse\": lin_mse})\n",
    "    mlflow.log_artifact(data_path)\n",
    "    print(\"Save to: {}\".format(mlflow.get_artifact_uri()))\n",
    "\n",
    "    mlflow.sklearn.log_model(lr, \"model\")\n",
    "    print(\"parent run:\")\n",
    "\n",
    "    print(\"run_id: {}\".format(parent_run.info.run_id))\n",
    "    print(\"description: {}\".format(parent_run.data.tags.get(\"mlflow.note.content\")))\n",
    "    print(\"version tag value: {}\".format(parent_run.data.tags.get(\"version\")))\n",
    "    print(\"priority tag value: {}\".format(parent_run.data.tags.get(\"priority\")))\n",
    "    print(\"--\")\n",
    "\n",
    "    # Search all child runs with a parent id\n",
    "    query = \"tags.mlflow.parentRunId = '{}'\".format(parent_run.info.run_id)\n",
    "    results = mlflow.search_runs(experiment_ids=[experiment_id], filter_string=query)\n",
    "    print(\"child runs:\")\n",
    "    print(results[[\"run_id\", \"params.child\", \"tags.mlflow.runName\"]])\n",
    "    #with mlflow.start_run(nested=True) as child_run:\n",
    "        # Execute ElasticNet\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could also do\n",
    "# with mlflow.start_run():\n",
    "#     for epoch in range(0, 3):\n",
    "#          mlflow.log_metric(key=\"quality\", value=2*epoch, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse 70191.42293514921\n",
      "Elasticnet model (alpha=0.500000, l1_ratio=0.500000):\n",
      "  RMSE: 70191.42293514921\n",
      "  MAE: 4926835853.660991\n",
      "Save to: /home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlruns/930564221674376619/a7312d1b7c4b48dc975943b3ec6836e8/artifacts\n",
      "parent run:\n",
      "run_id: 1d0356c6b5f84ff98abc9ba555f24e05\n",
      "description: parent\n",
      "version tag value: v1\n",
      "priority tag value: P1\n",
      "--\n",
      "child runs:\n",
      "                             run_id params.child tags.mlflow.runName\n",
      "0  c7239473932944ef945375966232735c          yes           CHILD_RUN\n"
     ]
    }
   ],
   "source": [
    "train(0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 1.2.2.\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticnet model (alpha=0.100000, l1_ratio=0.100000):\n",
      "  RMSE: 0.7792546522251949\n",
      "  MAE: 0.6112547988118587\n",
      "  R2: 0.2157063843066196\n",
      "Save to: /home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlruns/637260712838838962/82106880f36f4e50bfa920de3d091988/artifacts\n"
     ]
    }
   ],
   "source": [
    "train(0.1, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Comparing runs\n",
    "Run `mlflow ui` in a terminal or `http://your-tracking-server-host:5000` to view the experiment log and visualize and compare different runs and experiments. The logs and the model artifacts are saved in the `mlruns` directory (or where you specified)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Packaging the experiment as a MLflow project as conda env\n",
    "\n",
    "Specify the entrypoint for this project by creating a `MLproject` file and adding an conda environment with a `conda.yaml`. You can copy the yaml file from the experiment logs.\n",
    "\n",
    "To run this project, invoke `mlflow run . -P alpha=0.42`. After running this command, MLflow runs your training code in a new Conda environment with the dependencies specified in `conda.yaml`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deploy the model\n",
    "\n",
    "Deploy the model locally by running \n",
    "\n",
    "`mlflow models serve -m mlruns/0/f5f7c052ddc5469a852aa52c14cabdf1/artifacts/model/ -h 0.0.0.0 -p 1234`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the endpoint:\n",
    "\n",
    "`curl -X POST -H \"Content-Type:application/json; format=pandas-split\" --data '{\"columns\":[\"alcohol\", \"chlorides\", \"citric acid\", \"density\", \"fixed acidity\", \"free sulfur dioxide\", \"pH\", \"residual sugar\", \"sulphates\", \"total sulfur dioxide\", \"volatile acidity\"],\"data\":[[12.8, 0.029, 0.48, 0.98, 6.2, 29, 3.33, 1.2, 0.39, 75, 0.66]]}' http://0.0.0.0:1234/invocations`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also simply build a docker image from your model\n",
    "\n",
    "`mlflow models build-docker -m mlruns/1/d671f37a9c7f478989e67eb4ff4d1dac/artifacts/model/ -n elastic_net_wine`\n",
    "\n",
    "and run the container with\n",
    "\n",
    "`docker run -p 8080:8080 elastic_net_wine`.\n",
    "\n",
    "Or you can directly deploy to AWS sagemaker or Microsoft Azure ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tagging runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mlflow.tracking.client.MlflowClient object at 0x7fa8de6455d0>\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "experiment_id = \"0\"\n",
    "run = client.create_run(experiment_id)\n",
    "artifacts = client.list_artifacts(run.info.run_id)\n",
    "for artifact in artifacts:\n",
    "    print_artifact_info(artifact)\n",
    "client.set_terminated(run.info.run_id)\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Run: data=<RunData: metrics={'mae': 0.6155290394093895,\n",
      " 'r2': 0.20224631822892103,\n",
      " 'rmse': 0.7859129997062341}, params={'alpha': '0.2', 'l1_ratio': '0.2'}, tags={'mlflow.log-model.history': '[{\"run_id\": \"dec5fd9936e94e41b68a7109d4012132\", '\n",
      "                             '\"artifact_path\": \"model\", \"utc_time_created\": '\n",
      "                             '\"2023-03-23 09:49:28.800231\", \"flavors\": '\n",
      "                             '{\"python_function\": {\"model_path\": \"model.pkl\", '\n",
      "                             '\"predict_fn\": \"predict\", \"loader_module\": '\n",
      "                             '\"mlflow.sklearn\", \"python_version\": \"3.10.8\", '\n",
      "                             '\"env\": {\"conda\": \"conda.yaml\", \"virtualenv\": '\n",
      "                             '\"python_env.yaml\"}}, \"sklearn\": '\n",
      "                             '{\"pickled_model\": \"model.pkl\", '\n",
      "                             '\"sklearn_version\": \"1.2.2\", '\n",
      "                             '\"serialization_format\": \"cloudpickle\", \"code\": '\n",
      "                             'null}}, \"model_uuid\": '\n",
      "                             '\"845da25177c842cf886fc23bd72d79d4\", '\n",
      "                             '\"mlflow_version\": \"2.2.2\"}]',\n",
      " 'mlflow.runName': 'popular-quail-266',\n",
      " 'mlflow.source.git.commit': 'e2b91c798ba6034ffb7db7939e2f229ef81bd8ec',\n",
      " 'mlflow.source.name': '/home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlflow_tutorial/lib/python3.10/site-packages/ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'priyankathiruna'}>, info=<RunInfo: artifact_uri='/home/priyankathiruna/Ass_2.2/pydataberlin-2019/mlruns/637260712838838962/dec5fd9936e94e41b68a7109d4012132/artifacts', end_time=1679564970283, experiment_id='637260712838838962', lifecycle_stage='active', run_id='dec5fd9936e94e41b68a7109d4012132', run_name='popular-quail-266', run_uuid='dec5fd9936e94e41b68a7109d4012132', start_time=1679564968712, status='FINISHED', user_id='priyankathiruna'>>\n"
     ]
    }
   ],
   "source": [
    "# get the run\n",
    "_run = client.get_run(run_id=\"dec5fd9936e94e41b68a7109d4012132\")\n",
    "print(_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a tag to the run\n",
    "dt = datetime.now().strftime(\"%d-%m-%Y (%H:%M:%S.%f)\")\n",
    "client.set_tag(_run.info.run_id, \"deployed\", dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to a postgesql db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the db:\n",
    "    \n",
    "`sudo -u postgres psql`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a user and a database for the tracking server:\n",
    "    \n",
    "```\n",
    "CREATE DATABASE mlflow;\n",
    "CREATE USER mlflow WITH ENCRYPTED PASSWORD 'mlflow';\n",
    "GRANT ALL PRIVILEGES ON DATABASE mlflow TO mlflow;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "mlflow server --backend-store-uri postgresql://mlflow:mlflow@localhost/mlflow --default-artifact-root file:/home/tobias/Projects/mlflow_talk/pydataberlin-2019/mlruns/ -h 0.0.0.0 -p 8000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the notebook again with this tracking server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the db:\n",
    "\n",
    "`psql mlflow`\n",
    "\n",
    "`SELECT * FROM experiments;`\n",
    "\n",
    "`SELECT * FROM runs;`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
